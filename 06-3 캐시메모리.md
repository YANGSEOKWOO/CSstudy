> 프로그램을 실행하는 과정에서 메모리에 저장된 데이터를 빈번하게 사용한다.
> CPU가 메모리에 접근하는 시간은 CPU의 연산속도보다 느리다.
> 
> CPU의 연산시간과 메모리의 접근시간의 시간차이를 극복하기 위한 저장장치 : **캐시메모리**

### 거의 법칙?
속도와 용량은 양립하기 어렵다.
- CPU와 가까운 저장장치는 빠르다. 멀리 있는 저장장치는 느리다.
- 속도가 빠른 저장 장치는 저장 용량이 작고, 가격이 비싸다.

## 저장 장치 계층구조

레지스터를 생각해본다.

CPU와 가장 가까운 레지스터
- 장점 : 접근시간이 압도적 빠름
- 단점 : RAM보다 용량이 작다, 가격이 비싸다.

'CPU에 얼마나 가까운가를 기준으로 계층적으로 나눌 수 있다' : 저장장치 계층구조
![[Pasted image 20240218161515.png]]

#### 캐시 메모리
CPU가 아무리 빨라도, 메모리 접근속도가 느리니까 어떻게 해결할 수 있을까?

=> **캐시 메모리**
CPU와 메모리 사이에 위치하고, 레지스터보다 용량이 크고, 메모리보다 빠른 SRAM기반의 저장장치

CPU가 사용할 일부 데이터를 미리 캐시메모리로 가지고와서 활용하는 것

예를 들자면, 큰 쇼핑을 할 때는 대형마트에 가지만, 소규모가 필요할 때는 편의점에 가서 필요한 데이터만 가져오듯이

**잘 쓰는 데이터를 캐시메모리에 저장**하는 것!!

코어에 가장 가까운 순으로 L1, L2, L3캐시라고 부른다.
(일반적으로 L1, L2는 코어내부, L3는 코어 외부에 있다.)
![[Pasted image 20240218161824.png]]
용량, 가격
- L3 > L2 > L1
속도
- L1 > L2 > L3


#### 참조 지역성 원리

캐시는 메모리보다 용량이 적다.
캐시는 메모리의 일부를 복사하여 저장하는데, 어떤걸 저장해야 할까?

보조기억장치 : 전원이 꺼져도 기억할 대상을 저장한다.
메모리 : 실행 중인 대상을 저장한다.
**캐시 : CPU가 사용할 법한 대상을 예측하여 저장한다.**

예측한 데이터가 실제로 들어맞아 캐시 메모리 내 데이터가 CPU에 활용될 경우 **캐시히트** 라고 한다.

틀리게 된다면, 캐시에 갔다가 없어서 메모리에 가야하니까, 오히려 메모리에 바로 접근하는 것보다 성능이 떨어진다 => **캐시 미스**

어떤 원리에 의해 예측을 할까?
=> 참조 지역성의 원리

1. CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있다.
2. CPU는 접근한 메모리 공간 근처를 접근하려는 경향이 있다.

1번 예시를 들어봅시다

우리가 a라는 변수를 저장한다면, 메모리에 저장이 된다.
=> CPU는 변수가 저장된 메모리 공간을 언제든 다시 참조할 수 있다.

**시간 지역성**

2번 예시
![[Pasted image 20240218162549.png]]
프로그램 내에서 각각의 기능에 대한 데이터는 모여있다.
=> **공간 지역성**
